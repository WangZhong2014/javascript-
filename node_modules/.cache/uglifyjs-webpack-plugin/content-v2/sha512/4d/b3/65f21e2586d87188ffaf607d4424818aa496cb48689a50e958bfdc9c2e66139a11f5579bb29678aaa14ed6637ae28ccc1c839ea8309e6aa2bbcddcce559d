{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[103],{235:function(t,s,a){\"use strict\";a.r(s);var n=a(0),o=Object(n.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this,s=t.$createElement,a=t._self._c||s;return a(\"div\",{staticClass:\"content\"},[a(\"h1\",{attrs:{id:\"decode-streams-into-strings-the-right-way-tm\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#decode-streams-into-strings-the-right-way-tm\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" Decode streams into strings The Right Way(tm)\")]),a(\"pre\",{pre:!0,attrs:{class:\"language-javascript\"}},[a(\"code\",[a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"var\")]),t._v(\" fs   \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"require\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'fs'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"var\")]),t._v(\" zlib \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"require\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'zlib'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"var\")]),t._v(\" strs \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"require\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'stringstream'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\\n\"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"var\")]),t._v(\" utf8Stream \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" fs\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"createReadStream\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'massiveLogFile.gz'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n  \"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"pipe\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"zlib\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"createGunzip\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n  \"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"pipe\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"strs\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'utf8'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\")])]),a(\"p\",[t._v(\"No need to deal with \"),a(\"code\",[t._v(\"setEncoding()\")]),t._v(\" weirdness, just compose streams\\nlike they were supposed to be!\")]),a(\"p\",[t._v(\"Handles input and output encoding:\")]),a(\"pre\",{pre:!0,attrs:{class:\"language-javascript\"}},[a(\"code\",[a(\"span\",{attrs:{class:\"token comment\"}},[t._v(\"// Stream from utf8 to hex to base64... Why not, ay.\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"var\")]),t._v(\" hex64Stream \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" fs\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"createReadStream\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'myFile'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n  \"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"pipe\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"strs\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'utf8'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'hex'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n  \"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"pipe\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"strs\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'hex'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'base64'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\")])]),a(\"p\",[t._v(\"Also deals with \"),a(\"code\",[t._v(\"base64\")]),t._v(\" output correctly by aligning each emitted data\\nchunk so that there are no dangling \"),a(\"code\",[t._v(\"=\")]),t._v(\" characters:\")]),a(\"pre\",{pre:!0,attrs:{class:\"language-javascript\"}},[a(\"code\",[a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"var\")]),t._v(\" stream \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" fs\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"createReadStream\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'myFile'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"pipe\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"strs\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'base64'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\\n\"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"var\")]),t._v(\" base64Str \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"''\")]),t._v(\"\\n\\nstream\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"on\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'data'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"function\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"data\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\" base64Str \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"+=\")]),t._v(\" data \"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\nstream\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"on\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'end'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"function\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  console\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"log\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'My base64 encoded file is: '\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" base64Str\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token comment\"}},[t._v(\"// Wouldn't work with setEncoding()\")]),t._v(\"\\n  console\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"log\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'Original file is: '\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token class-name\"}},[t._v(\"Buffer\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"base64Str\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token string\"}},[t._v(\"'base64'\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\"\\n\")])])])}],!1,null,null,null);s.default=o.exports}}]);","extractedComments":[]}